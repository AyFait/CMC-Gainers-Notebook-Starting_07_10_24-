{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9415160,"sourceType":"datasetVersion","datasetId":5374348}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayfait/cmc-gainers-notebook-starting-07-10-24?scriptVersionId=215140772\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# I wrote this first code on Kaggle to create a program that will compile a list of **Coinmarketcap daily gainers**.\nI already wrote a code for the Top10 gainers treemap [here](https://github.com/AyFait/Cmc_Scrape_Top10_HeatMap_TreeMap)\n\n\n### Be kind enough to leave an upvote if you found this insightful and helpful. cheers...","metadata":{}},{"cell_type":"markdown","source":"# Installing chrome browser for the virtual environment\n","metadata":{}},{"cell_type":"code","source":"#installing chrome browser for the virtual environment\n!apt-get update\n!apt-get install -y wget unzip\n!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n!dpkg -i google-chrome-stable_current_amd64.deb\n!apt-get -f install -y","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-12-28T11:34:33.651451Z","iopub.execute_input":"2024-12-28T11:34:33.65174Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,196 kB]\nGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nGet:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nGet:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,566 kB]                       \nGet:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]              \nGet:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]       \nGet:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,517 kB]              \nGet:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                          \nHit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease                        \nGet:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]   \nGet:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]            \nGet:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.4 kB]\nGet:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]          \nGet:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,448 kB]        \nGet:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,840 kB]                \nGet:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,631 kB]                    \nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,633 kB]          \nGet:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\nFetched 28.2 MB in 4s (6,392 kB/s)                           \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nunzip is already the newest version (6.0-26ubuntu3.2).\nwget is already the newest version (1.21.2-2ubuntu1.1).\n0 upgraded, 0 newly installed, 0 to remove and 136 not upgraded.\n--2024-12-28 11:34:43--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\nResolving dl.google.com (dl.google.com)... 64.233.188.91, 64.233.188.93, 64.233.188.190, ...\nConnecting to dl.google.com (dl.google.com)|64.233.188.91|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 112770956 (108M) [application/x-debian-package]\nSaving to: ‘google-chrome-stable_current_amd64.deb’\n\ngoogle-chrome-stabl 100%[===================>] 107.55M   358MB/s    in 0.3s    \n\n2024-12-28 11:34:43 (358 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [112770956/112770956]\n\nSelecting previously unselected package google-chrome-stable.\n(Reading database ... 127365 files and directories currently installed.)\nPreparing to unpack google-chrome-stable_current_amd64.deb ...\nUnpacking google-chrome-stable (131.0.6778.204-1) ...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Installing chromedriver","metadata":{}},{"cell_type":"code","source":"#installing chromedriver\n!wget https://chromedriver.storage.googleapis.com/113.0.5672.63/chromedriver_linux64.zip\n!unzip chromedriver_linux64.zip\n!mv chromedriver /usr/bin/chromedriver\n!chmod +x /usr/bin/chromedriver \n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Installing selenium","metadata":{}},{"cell_type":"code","source":"#installing selenium\n!pip install --upgrade jupyter-lsp\n!pip install --upgrade selenium\n!pip install webdriver-manager\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing modules and packages","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nfrom kaggle_secrets import UserSecretsClient\n\nimport pandas as pd\nimport time\nfrom datetime import datetime\nimport numpy as np\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up Chrome options\nchrome_options = Options()\nchrome_options.add_argument(\"--headless\")  # Run in headless mode.\nchrome_options.add_argument(\"--no-sandbox\")\nchrome_options.add_argument(\"--disable-dev-shm-usage\")\nchrome_options.add_argument(\"--remote-debugging-port=9222\")  # This line helps in some environments\nchrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n\n# Initialize WebDriver\ndriver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n\n\n# Test the WebDrive\nurl='https://coinmarketcap.com/gainers-losers/'\ndriver.get(url)\nprint(driver.title)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#define url of page to exract data from\nurl='https://coinmarketcap.com/gainers-losers/'\ndriver.get(url)\ntime.sleep(5) #Sleep for few seconds so, by that time, the webpage gets loaded.\nranking =  driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/div[2]/div/div[2]/div/div[2]/div/div[1]/div/table')# get element by XPATH from element selection in inspect mode\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = []  # Extract data\nfor index, rank in enumerate(ranking):\n    rowData = rank.text.split('\\n')\n    #print(rowData) #This prints the extracted data all in a single row\n    data.append(rowData)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Resahaping the data list to # cols\nlst_cleaned = rowData[5:] #popping headers\nexpectedRows = len(lst_cleaned) // 4 #divide the list by no of expected cols to get no of expected rows\nlst_array = np.array(lst_cleaned)#turning the simngle rowdata list into an array\nreshpd = lst_array.reshape(int(expectedRows), 4) #to get row x col\nreshpdtrimmed = reshpd[:, :-1]#'Price' '24h%' 'Vol(24h)' were merged together so I popped them\nforth = np.array([row[3].split() for row in reshpd])#now splitting 'Price' '24h%' 'Vol(24h)' on their own\nlst_n_forth = np.concatenate((reshpdtrimmed, forth), axis = 1)#joining them back together","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"expectedRows = len(lst_cleaned) // 4 #divide the list by no of expected cols to get no of expected rows\nlst_array = np.array(lst_cleaned)#turning the simngle rowdata list into an array\nreshpd = lst_array.reshape(int(expectedRows), 4) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Adding TimeStamp for each row\ntiming = []\nfor i in range(len(lst_n_forth)):\n    timestamp = datetime.utcnow().strftime('%m/%d/%Y %H:%M:%S UTC')\n    timing.append(timestamp)\n#print(timing)\ntiming_array = np.array(timing)    \ntimingreshpd = timing_array.reshape(len(timing), 1)\ntimed_array = np.concatenate((timingreshpd, lst_n_forth), axis = 1)#coming together making the perfect array with timestamp\n#print(len(timed_array))\n#print(timed_array)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#passing to nympy Dataframe to get tabular form\nnew_ver_csv = pd.DataFrame(timed_array,index=np.arange(1, len(timed_array)+1), columns=['Time_Stamp', 'CMC_Rank', 'Name', 'Symbol', 'Price($)', '24h%', '24h_Vol($)'])\nnew_ver_csv['Price($)'] = new_ver_csv['Price($)'].str.lstrip('$').str.replace(',', '').astype(float)\nnew_ver_csv['24h%'] = new_ver_csv['24h%'].str.rstrip('%').str.replace(',', '').astype(float)\nnew_ver_csv['24h_Vol($)'] = new_ver_csv['24h_Vol($)'].str.lstrip('$').str.replace(',', '').astype(float)\n#print(df)\ntimestamp = datetime.utcnow().strftime('%b %d, %Y %H:%M:%S UTC')\ntitle = f\"CMC 24h% Increase for {timestamp}\"\ndisplay_title = f\"**{title}**\"\n# Display the title and DataFrame as a Markdown\nfrom IPython.display import display, Markdown\ndisplay(Markdown(display_title))\ndisplay(new_ver_csv)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs('/kaggle/dataset/', exist_ok=True)\n\n#First load exixting csv from input\nold_ver_csv_path = '/kaggle/input/cmc-gain-dataset/CMC_24h_Gainers_Starting_07_10_24 updated.csv'\n#new_csv_file_path = f'/kaggle/dataset/CMC_24h_Gainers_Starting_07_10_24 updated.csv'\nnew_csv_file_path = f'/kaggle/dataset/CMC_24h_Gainers_Starting_07_10_24 updated.csv'\n\n\nif not os.path.isfile(old_ver_csv_path):\n    new_ver_csv.to_csv(new_csv_file_path)\n    \nelse:\n    #Load the older version of the csv file\n    old_ver_csv = pd.read_csv(old_ver_csv_path)\n    #remove the existing index of the old csv file\n    old_ver_csv = old_ver_csv.iloc[:, 1:]\n    #Join old and new csv files\n    joined = pd.concat([old_ver_csv, new_ver_csv], axis=0)\n    #This line keeps creating new index on each run\n    joined.index = range(1, len(joined)+1)\n    #joined.reset_index(drop=True, inplace=True)\n\n    \ndisplay(joined)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Check if the file exists in dataset folder\nif not os.path.isfile(new_csv_file_path):\n    #Create new\n    joined.to_csv(new_csv_file_path)#with index\n    #joined.to_csv(new_csv_file_path, index=False)#without index\nelse:\n    #Append to existing     \n    joined.to_csv(new_csv_file_path, mode='a', header=False, index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Setting up environment variables in order to use the kaggle CLI to automate upoloading of the dataset\n\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#From the folder that holds the dataset and creating the metadata file, It must NOT be the working dir else Unncessary files will be uploaded too:\n\nmeta = dict(\n    id=\"ayfait/CMC-Gain-Dataset\",\n    title=\"CMC Gainers Dataset Starting_07_11_2024\",\n    isPrivate=False,\n    licenses=[dict(name=\"apache-2.0\")]\n)\n\nwith open('/kaggle/dataset/dataset-metadata.json', 'w') as f:\n    json.dump(meta, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#To upload the dataset created inside /kaggle/dataset for the first time:\n#!kaggle datasets create -p \"/kaggle/dataset\" --dir-mode zip\n\n#To push a new version of the dataset \n!kaggle datasets version -p \"/kaggle/dataset\" -m \"Updated via notebook\" --dir-mode zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#To clean directory\n#rm -rf /kaggle/working/*\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}