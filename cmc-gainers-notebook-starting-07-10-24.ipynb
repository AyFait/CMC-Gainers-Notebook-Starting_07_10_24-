{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayfait/cmc-gainers-notebook-starting-07-10-24?scriptVersionId=187818824\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"I'm writing this first code on Kaggle to create a program that will compile a list of **Coinmarketcap daily gainers**.\nI already wrote a code for the Top10 gainers treemap [here](https://github.com/AyFait/Cmc_Scrape_Top10_HeatMap_TreeMap)","metadata":{}},{"cell_type":"code","source":"#installing chrome\n!apt-get update\n!apt-get install -y wget unzip\n!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n!dpkg -i google-chrome-stable_current_amd64.deb\n!apt-get -f install -y","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-07-11T11:46:17.789394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#installing chromedriver\n!wget https://chromedriver.storage.googleapis.com/113.0.5672.63/chromedriver_linux64.zip\n!unzip chromedriver_linux64.zip\n!mv chromedriver /usr/bin/chromedriver\n!chmod +x /usr/bin/chromedriver\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#insatlling selenium\n!pip install --upgrade jupyter-lsp\n!pip install --upgrade selenium\n!pip install webdriver-manager\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport time\nfrom datetime import datetime\nimport numpy as np\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up Chrome options\nchrome_options = Options()\nchrome_options.add_argument(\"--headless\")  # Run in headless mode.\nchrome_options.add_argument(\"--no-sandbox\")\nchrome_options.add_argument(\"--disable-dev-shm-usage\")\nchrome_options.add_argument(\"--remote-debugging-port=9222\")  # This line helps in some environments\nchrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n\n# Initialize WebDriver\ndriver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n\n\n# Test the WebDrive\nurl='https://coinmarketcap.com/gainers-losers/'\ndriver.get(url)\nprint(driver.title)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define url of page to exract data from\nurl='https://coinmarketcap.com/gainers-losers/'\ndriver.get(url)\ntime.sleep(5) #Sleep for few seconds so, by that time, the webpage gets loaded.\nranking =  driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/div[2]/div/div[2]/div/div[2]/div/div[1]/div/table')# get element by XPATH from element selection in inspect mode\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []  # Extract data\nfor index, rank in enumerate(ranking):\n    rowData = rank.text.split('\\n')\n    #print(rowData) #This prints the extracted data all in a single row\n    data.append(rowData)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resahaping the data list to # cols\nlst_cleaned = rowData[5:] #popping headers\nexpectedRows = len(lst_cleaned) // 4 #divide the list by no of expected cols to get no of expected rows\nlst_array = np.array(lst_cleaned)#turning the simngle rowdata list into an array\nreshpd = lst_array.reshape(int(expectedRows), 4) #to get row x col\nreshpdtrimmed = reshpd[:, :-1]#'Price' '24h%' 'Vol(24h)' were merged together so I popped them\nforth = np.array([row[3].split() for row in reshpd])#now splitting 'Price' '24h%' 'Vol(24h)' on their own\nlst_n_forth = np.concatenate((reshpdtrimmed, forth), axis = 1)#joining them back together","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding TimeStamp for each row\ntiming = []\nfor i in range(len(lst_n_forth)):\n    timestamp = datetime.utcnow().strftime('%m/%d/%Y %H:%M:%S UTC')\n    timing.append(timestamp)\n#print(timing)\ntiming_array = np.array(timing)    \ntimingreshpd = timing_array.reshape(30, 1)\ntimed_array = np.concatenate((timingreshpd, lst_n_forth), axis = 1)#coming together making the perfect array with timestamp\n#print(len(timed_array))\n#print(timed_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#passing to nympy Dataframe to get tabular form\ndf = pd.DataFrame(timed_array,index=np.arange(1, len(timed_array)+1), columns=['Time_Stamp', 'CMC_Rank', 'Name', 'Symbol', 'Price($)', '24h%', '24h_Vol($)'])\ndf['Price($)'] = df['Price($)'].str.lstrip('$').astype(float)\ndf['24h%'] = df['24h%'].str.rstrip('%').astype(float)\ndf['24h_Vol($)'] = df['24h_Vol($)'].str.lstrip('$').str.replace(',', '').astype(float)\n#print(df)\ntimestamp = datetime.utcnow().strftime('%b %d, %Y %H:%M:%S UTC')\ntitle = f\"Top 10 CMC 24h% Increase for {timestamp}\"\ndisplay_title = f\"**{title}**\"\n# Display the title and DataFrame as a Markdown\nfrom IPython.display import display, Markdown\ndisplay(Markdown(display_title))\ndisplay(df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The first list created\ndf.to_csv(f'/kaggle/dataset/CMC_24h_Gainers_Starting_07_10_24 updated - {timestamp}.csv', index=False)\n\n#To append to the list\n#df.to_csv(f'/kaggle/dataset/CMC_24h_Gainers_Starting_07_10_24 updated - {timestamp}.csv',mode='a', header=False, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting up environment variables in order to use the kaggle CLI to automate upoloading of the dataset\nimport os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\n\n\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating the folder that will hold the dataset and create the metadata file:\nos.makedirs('/kaggle/dataset/', exist_ok=True)\n\n\n# Change below\nmeta = dict(\n    id=\"ayfait/my-dataset\",\n    title=\"CMC Gainers Dataset Starting_07_11_2024\",\n    isPrivate=False,\n    licenses=[dict(name=\"Apache 2.0\")]\n)\n\nwith open('/kaggle/dataset/dataset-metadata.json', 'w') as f:\n    json.dump(meta, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To upload the dataset created inside /kaggle/dataset for the first time:\n!kaggle datasets create -p \"/kaggle/dataset\" --dir-mode zip\n\n#To push a new version of the dataset \n#!kaggle datasets version -p \"/kaggle/dataset\" -m \"Updated via notebook\" --dir-mode zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}